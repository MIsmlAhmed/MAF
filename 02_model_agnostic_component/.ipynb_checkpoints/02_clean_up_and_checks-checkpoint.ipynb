{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2793c999-4546-4ec5-ab2a-f74329725ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456bd4f9-071d-463e-8cfb-62d8d60d38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "path_general = '/scratch/mia725/calibration_workflow/Smoky_river/gistool-outputs/'\n",
    "num_land_cover = 19\n",
    "minimume_land_fraction = 0.05 # fraction of land cover under which the fraction is set to 0 and other fractions are normalized\n",
    "num_soil_type = 12\n",
    "unify_soil = True # if soil is not used in GRU creation, set to true to True, all the subbasin will be allocated by most dominant soil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4cf80-6f3d-4481-add3-43278a46879c",
   "metadata": {},
   "source": [
    "### sanity check for soil type. It is possible that the soil type is set to 0 or unknown for lakes or water bodies. In this study we replace that with the majority of soil type in the domain (including possible NaN values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4162587b-f59b-40e5-a985-e358bd6fbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_soil_type = path_general + 'domain_stats_soil_classes.csv'\n",
    "path_landcover_type = path_general + 'domain_stats_NA_NALCMS_landcover_2020_30m.csv'\n",
    "path_elevation_mean = path_general + 'domain_stats_elv.csv'\n",
    "\n",
    "soil_type = pd.read_csv(path_soil_type)\n",
    "landcover_type = pd.read_csv(path_landcover_type)\n",
    "elevation_mean = pd.read_csv(path_elevation_mean)\n",
    "\n",
    "# # should be removed when gistool is fixed for mertihydro\n",
    "# from copy import deepcopy\n",
    "# elevation_mean = deepcopy(soil_type)\n",
    "# elevation_mean = elevation_mean[['COMID']]\n",
    "# elevation_mean['min']=1;elevation_mean['max']=10;elevation_mean['mean']=5;elevation_mean['median']=5\n",
    "# if not os.path.isdir(path_general+'merit_hydro'):\n",
    "#     os.makedirs(path_general+'merit_hydro')\n",
    "# elevation_mean.to_csv(path_general + 'merit_hydro/domain_stats_elv.csv')\n",
    "\n",
    "soil_type = soil_type.sort_values(by='COMID').reset_index(drop=True)\n",
    "landcover_type = landcover_type.sort_values(by='COMID').reset_index(drop=True)\n",
    "elevation_mean = elevation_mean.sort_values(by='COMID').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629ce44-9429-48f5-9cb9-ad49739081d1",
   "metadata": {},
   "source": [
    "# check if all the COMID are similar in all the three files (from similar shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed27eba6-2b0d-4f28-8a88-1a3350ef5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if COMIDs are the similar\n",
    "# check the len\n",
    "if len(soil_type) != len(landcover_type) or len(landcover_type) != len(elevation_mean):\n",
    "    sys.exit('The provided length of soil and land cover is not identical')\n",
    "\n",
    "# check if the COMIDs are similar\n",
    "if sum(soil_type['COMID'].values - landcover_type['COMID'].values) != 0 or \\\n",
    "sum(landcover_type['COMID'].values - elevation_mean['COMID'].values) != 0:\n",
    "    sys.exit('The COMID of the shapefile in soil and land cover is not identical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619ab3b-71ae-4a29-b572-1b673936ba28",
   "metadata": {},
   "source": [
    "# soil maps sanity check\n",
    "\n",
    "### if there is NaN replace with majority soil types in the domain\n",
    "### if there is 0, unidentified, replae with majority soil types in the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b665b455-f80b-4a0a-ad19-7592dae100e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all values in 'majority' are either NaN or zero\n",
    "is_all_nan_or_zero = soil_type['majority'].isnull().all() or (soil_type['majority'] == 0).all()\n",
    "\n",
    "if is_all_nan_or_zero:\n",
    "    sys.exit(\"All values in 'majority' are either NaN or zero.\")\n",
    "    \n",
    "# check if there is NaN in values\n",
    "has_nan = soil_type['majority'].isna().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The 'majority' column has NaN values will be replace with majority.\")\n",
    "\n",
    "# Find the majority value excluding NaN and zeros\n",
    "majority_value = soil_type['majority'].replace(0, np.nan).mode().iloc[0]\n",
    "\n",
    "# Replace 0 values with the majority value\n",
    "soil_type['majority'] = soil_type['majority'].replace(0, majority_value)\n",
    "\n",
    "# Replace NaN values with the majority value\n",
    "soil_type['majority'].fillna(majority_value, inplace=True)\n",
    "\n",
    "# unify soil\n",
    "if unify_soil:\n",
    "    soil_type['majority'] = majority_value\n",
    "\n",
    "# save the modified file\n",
    "# get the file name and it path separaeted:\n",
    "path_soil_type_path_name = os.path.dirname(path_soil_type)\n",
    "path_soil_type_file_name = os.path.basename(path_soil_type)\n",
    "soil_type.to_csv(path_soil_type_path_name+'/modified_'+path_soil_type_file_name, index=False)\n",
    "#soil_type.to_csv(path_soil_type_path_name+'/'+path_soil_type_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9c728-1bd1-4d22-b801-c992219f10e5",
   "metadata": {},
   "source": [
    "# land cover map\n",
    "\n",
    "### land cover map rescaling for fraction larger than a given minimum fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3acdc16-e092-4750-b717-026d17f7308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# land cover sanity check and renormalization\n",
    "# Possible normalization of land cover fraction above a certain threshold\n",
    "for col in landcover_type.columns:\n",
    "    if col.startswith('frac_'):\n",
    "        landcover_type[col] = landcover_type[col].apply(lambda x: 0 if x < minimume_land_fraction else x)\n",
    "\n",
    "# Second iteration: Normalize non-zero values based on row sums\n",
    "for index, row in landcover_type.iterrows():\n",
    "    frac_columns = [col for col in landcover_type.columns if col.startswith('frac_')]\n",
    "    row_sum = row[frac_columns].sum()\n",
    "    if row_sum > 0:\n",
    "        for col in frac_columns:\n",
    "            landcover_type.at[index, col] /= row_sum\n",
    "            \n",
    "# add non existing columns and one line of non zero values\n",
    "missing_columns = [f\"frac_{i}\" for i in range(1, num_land_cover+1) if f\"frac_{i}\" not in landcover_type.columns]\n",
    "for col in missing_columns:\n",
    "    landcover_type[col] = 0\n",
    "    \n",
    "# Sort columns that start with \"frac_\" based on the numbers at the end\n",
    "frac_columns = [col for col in landcover_type.columns if re.match(r'^frac_\\d+$', col)]\n",
    "frac_columns.sort(key=lambda x: int(re.search(r'\\d+$', x).group()))\n",
    "\n",
    "# Reorder DataFrame columns with sorted \"frac_\" columns\n",
    "sorted_columns = [col for col in landcover_type.columns if col not in frac_columns] + frac_columns\n",
    "landcover_type = landcover_type.reindex(columns=sorted_columns)\n",
    "\n",
    "# replace the first line zeros with minimum values for CLASS to run\n",
    "for col in frac_columns:\n",
    "    if landcover_type.loc[0, col] < 0.00001:\n",
    "        landcover_type.loc[0, col] = 0.00001\n",
    "            \n",
    "# save the modified file\n",
    "# get the file name and it path separaeted:\n",
    "path_landcover_type_path_name = os.path.dirname(path_landcover_type)\n",
    "path_landcover_type_file_name = os.path.basename(path_landcover_type)\n",
    "landcover_type.to_csv(path_landcover_type_path_name+'/modified_'+path_landcover_type_file_name, index=False)\n",
    "#landcover_type.to_csv(path_landcover_type_path_name+'/'+path_landcover_type_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df43e986-6caa-4ec5-9bf2-0527c06308ba",
   "metadata": {},
   "source": [
    "# Mean value of elevation set to zero if NaN (wont affect mizuRoute routing).\n",
    "\n",
    "### assumes the shapfile in open water or sea level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f42c90-7317-4f88-b4cf-d9f2f9055a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan = elevation_mean['mean'].isna().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The 'mean' column has NaN values will be replace by 0.\")\n",
    "    \n",
    "elevation_mean['mean'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# save the modified file\n",
    "# get the file name and it path separaeted:\n",
    "path_elevation_mean_path_name = os.path.dirname(path_elevation_mean)\n",
    "path_elevation_mean_file_name = os.path.basename(path_elevation_mean)\n",
    "elevation_mean.to_csv(path_elevation_mean_path_name+'/modified_'+path_elevation_mean_file_name, index=False)\n",
    "#elevation_mean.to_csv(path_elevation_mean_path_name+'/'+path_elevation_mean_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6bcaf-fd20-4037-8df8-11785c6b1c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienv",
   "language": "python",
   "name": "scienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
