{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cee08e-980e-4a76-b41c-bfffd7f39f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bf61fc-58ea-417b-9693-1c09211e4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_org = '/scratch/mia725/calibration_workflow/Bow_Banff/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e909e3-26ce-4337-81d9-ebf6a3beec23",
   "metadata": {},
   "source": [
    "# create filedir.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e48e24f-8887-4321-9570-adee591a1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = path_org+'HYPE/filedir.txt'\n",
    "\n",
    "if os.path.isfile(output_file):\n",
    "    os.remove(output_file)\n",
    "    \n",
    "with open(output_file, 'w') as file:\n",
    "        file.write('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d15f7f-f33b-4930-911c-ff191bf70483",
   "metadata": {},
   "source": [
    "# create par file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6fc2bc-79d1-4e29-b784-d1f072c59f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output par to a .txt file\n",
    "\n",
    "output_file = path_org+'HYPE/info.txt'\n",
    "if os.path.isfile(output_file):\n",
    "    os.remove(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa12a52a-91cc-426f-a6eb-0a349a99ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define start time, end time, based on input forcing\n",
    "# spinup period is a user defined inputs\n",
    "spinup_days = 30\n",
    "Pobs = pd.read_csv(path_org+'HYPE/Pobs.txt', sep='\\t', parse_dates=['time'])\n",
    "Pobs['time'] = Pobs['time'].dt.date\n",
    "start_date = Pobs['time'].iloc[0]\n",
    "end_date = Pobs['time'].iloc[-1]\n",
    "spinup_date = start_date + pd.Timedelta(days=spinup_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af49ae4-a78e-4e06-85eb-1e6cbf41319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out first text section\n",
    "s1= [\n",
    "\"\"\"!! ----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! HYPE - Milk River & St. Mary's River HYPE\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!! Check Indata during first runs (deactivate after first runs) \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d99401c-e25a-429b-be6a-994a41bf43ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s1 in output file\n",
    "with open(output_file, 'w') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s1:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205500a5-e91a-4abe-988e-f029335c6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create first dataframe\n",
    "df1_row=['indatacheckonoff','indatachecklevel']\n",
    "df1_val=[2,2]\n",
    "df1=pd.DataFrame(df1_val, index=df1_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7647a9-9627-4801-84c2-936bf1310d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df1\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df1.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a28d7f-1100-47fe-8d15-70d41c1be395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out first text section\n",
    "s2= [\n",
    "\"\"\"!!\n",
    "!! -----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\n",
    "!! Simulation settings:\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db40330b-d3d7-4ec6-8952-2085748fe319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s2 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s2:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7579c977-b0ad-4dfa-8eb8-549d61708f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df2\n",
    "df2_row=['bdate','cdate','edate','resultdir','instate', 'warning']\n",
    "df2_val=[start_date,spinup_date,end_date,'/results/', 'n','y']\n",
    "df2=pd.DataFrame(df2_val, index=df2_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9761a51d-0c85-4331-992e-3961e240a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df2\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df2.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ed759b-314b-48b5-a611-fd7762706264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s3\n",
    "s3= [\n",
    "\"\"\"!! outstatedate \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "150172bd-0247-465b-8e02-dc6eadcca90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s3 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s3:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c5e14cb-a7c7-499d-ba49-2b44ff90178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df3\n",
    "df3_row=['readdaily','submodel','calibration','readobsid','soilstretch']\n",
    "df3_val=['n','n','n','n','n']\n",
    "df3=pd.DataFrame(df3_val, index=df3_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50349926-e965-4ccd-bdc3-29a5ff24aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df3\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df3.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c096930-3c12-4da4-b921-cc54998dabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s4\n",
    "s4= [\n",
    "\"\"\"!! Soilstretch enable the use of soilcorr parameters (strech soildepths in layer 2 and 3)\n",
    "steplength\t1d\t\t\t\t\t\t\t\n",
    "!! -----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! Enable/disable optional input files\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d9b038a-4585-47f9-8b51-76016e506283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s4 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s4:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a53d9cd7-30f8-424a-ae17-78df5c2496e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df4\n",
    "df4_row=['readsfobs','readswobs','readuobs','readrhobs','readtminobs','readtmaxobs','soiliniwet','usestop84']\n",
    "df4_val=['n','n','n','n','n','n','n','n']\n",
    "df4=pd.DataFrame(df4_val, index=df4_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f55ba3a9-0514-4664-8b0c-d19d3736b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the corresponding comments\n",
    "c1 = [\n",
    "    \"!! For observed snowfall fractions in SFobs.txt\",\n",
    "    \"!! For observed shortwave radiation in SWobs.txt\",\n",
    "    \"!! For observed wind speeds in Uobs.txt\",\n",
    "    \"!! For observed relative humidity in RHobs.txt\",\n",
    "    \"!! For observed min air temperature in TMINobs.txt\",\n",
    "    \"!! For observed max air temperature in TMAXobs.txt\",\n",
    "    \"!! initiates soil water to porosity instead of field capacity which is default (N). Set Y to use porosity.\",\n",
    "    \"!! initiates soil water to porosity instead of field capacity which is default (N). Set Y to use porosity.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d41a92c-9a98-49a1-9b88-c2ff3b78e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append c1 and df4\n",
    "with open(output_file, 'a') as file:\n",
    "    # Iterate over DataFrame rows\n",
    "    for i, (index, row) in enumerate(df4.iterrows()):\n",
    "        # Check if there is a comment line for the current row\n",
    "        if i < len(c1):\n",
    "            # Write the row name, values, and comment on the same line\n",
    "            line = str(index) + '\\t' + '\\t'.join(str(val) for val in row.values) + '\\t' + c1[i] + '\\n'\n",
    "        else:\n",
    "            # Write the row name and values without comment on the same line\n",
    "            line = str(index) + '\\t' + '\\t'.join(str(val) for val in row.values) + '\\n'\n",
    "        \n",
    "        # Write the line to the file\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47386d0b-4919-4399-9a89-c2227d2fe500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s5\n",
    "s5= [\n",
    "\"\"\"!! -----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! Define model options (optional)\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!!snowfallmodel:\t\t\t\t\t\t\t\t\n",
    "!!                  0 threshold temperature model\t\t\t\t\t\t\t\n",
    "!!                  1 inputdata (SFobs.txt)\t\t\t\t\t\t\t\n",
    "!!snowmeltmodel:\t\t\t\t\t\t\t\n",
    "!!                  0,1 temperature index             (with/without snowcover scaling)\t\t\t\t\t\t\t\n",
    "!!                  2   temperature + radiation index (with/without snowcover scaling)\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!!  snowevapmodel   0 off\t\t\t\t\t\t\t\n",
    "!!                  1 on\t\t\t\t\t\t\t\n",
    "!!                   \t\t\t\t\t\t\t\n",
    "!!  petmodel:  (potential evapotranspiration) (is shown in geodata for WWH)\t\t\t\t\t\t\t\n",
    "!!                  0 original HYPE temperature model (with Xobs epot replacement)\t\t\t\t\t\t\t\n",
    "!!                  1 original HYPE temperature model (without Xobs epot replacement)\t\t\t\t\t\t\t\n",
    "!!                  2 Modified Jensen-Haise \t\t\t\t\t\t\t\n",
    "!!                  3 Modified Hargreaves-Samani\t\t\t\t\t\t\t\n",
    "!!                  4 Priestly-Taylor\t\t\t\t\t\t\t\n",
    "!!                  5 FAo Penman-Monteith\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! lakeriverice:\t\t\t\t\t\t\t\n",
    "!!                  0 off\t\t\t\t\t\t\t\n",
    "!!                  1 on, old (simple) air-water heat exchange              (requires T2 water temperature model)\t\t\t\t\t\t\t\n",
    "!!                  2 on, new heatbalance model for air-water heat exchange (requires T2 water temperature model)\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! substance T2     switching on the new water temperature trace model\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! deepground       0   off    Deep groundwater (Aquifer) model options\t\t\t\t\t\t\t\n",
    "!!                  1,2 on\n",
    "!! Glacierini\t0 off 1 on\t(1 used for statefile preparation)\t\n",
    "!! Floodplain\t\t0, 1, 2, 3 (3 used for WWH)\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c88f024-b468-43cf-8c6a-fe213db79409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s5 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s5:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9daac7dd-bb7d-41a1-a027-7c961d20b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df5\n",
    "df5_row=['modeloption snowfallmodel','modeloption snowdensity','modeloption snowfalldist',\n",
    "         'modeloption snowheat','modeloption snowmeltmodel','modeloption snowevaporation','modeloption lakeriverice',\n",
    "         'modeloption deepground','modeloption glacierini','modeloption frozensoil',\n",
    "         'modeloption infiltration','modeloption surfacerunoff','modeloption petmodel',\n",
    "         'modeloption riverflowmodel','modeloption soilleakage']\n",
    "df5_val=[0,0,0,1,2,1,0,0,1,2,3,0,1,0,0]\n",
    "df5=pd.DataFrame(df5_val, index=df5_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a03c40b8-ba13-4871-9b1f-35b64e3253c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df5\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df5.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20217760-e459-40a1-bf06-8c447f76038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s6\n",
    "s6= [\n",
    "\"\"\"!! ------------------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! Define outputs\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!! meanperiod 1=daymean, 2=weekmean, 3=monthmean, 4=yearmean, 5=total period mean\t\t\t\t\t\t\t\n",
    "!! output variables: see http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables \n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!! BASIN outputs \n",
    "!! The present basins are some large rivers distributed over different continents\n",
    "!! -----------------\t\t\t\t\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dd363e1-65e8-4ef7-af75-402185642004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s6 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s6:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebd6d0ac-0161-4e9f-a901-7da01cbde49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6={'!! basinoutput variable': 'cout\\trout\\tctmp\\tsnow\\tsdep\\tsoim\\tsom2\\tsml1\\tsml2\\tsml3\\tsmrz\\tsm13\\tstsw\\tsrff\\tsmfd\\tsrfd\\tsmfp\\tsrfp\\tsmdf\\tgwat\\tsfst\\tstmp\\tstm1\\tstm2\\tstm3\\tcfsc\\tsmax\\tcilv\\tclbv\\tcgwl\\tcloc\\tclof\\tclrv\\tcmrv\\tqerr\\tcobc\\tcmri\\tclri\\tcmrb\\tclrb\\tcmrs\\tclrs\\tclic\\tglcv\\tglca\\tlrdp\\tmrdp\\tcgmb\\tcgma\\tC106\\tC108\\tC111\\tC114\\tC206\\tC208\\tC211\\tC214\\tcoT1\\tcoT2\\tcprc\\tcpSF\\tcpRF\\tevap\\tepot\\ticpe\\tevsn\\tlevp\\tevpt\\tpsim\\tcrun\\tcro1\\tcro2\\tcro3\\tcrod\\tcros\\tros1\\tros2\\tacdf\\taqin\\taqut\\tspeq\\tgmlt\\tloff\\tlrfa\\tmrfa\\tlred\\tmred\\tinfi\\tsnwc\\tsnht\\tsnte\\tsnts\\tdtmp\\tcmrp\\tcrgl\\tcrnt\\tcmrr\\tcrpt\\tcrex\\tpsub\\tesub\\tisub\\tcmrq',\n",
    "     '!! basinoutput meanperiod':1,\n",
    "     '!! basinoutput decimals':3,\n",
    "     '!! basinoutput subbasin':'subid1\\tsubid2\\tsubid3\\tsubid4',\n",
    "     '!! printwaterbal':'N' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38cc95e5-110c-41a2-b1a1-f454e2ed3607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!! basinoutput variable': 'cout\\trout\\tctmp\\tsnow\\tsdep\\tsoim\\tsom2\\tsml1\\tsml2\\tsml3\\tsmrz\\tsm13\\tstsw\\tsrff\\tsmfd\\tsrfd\\tsmfp\\tsrfp\\tsmdf\\tgwat\\tsfst\\tstmp\\tstm1\\tstm2\\tstm3\\tcfsc\\tsmax\\tcilv\\tclbv\\tcgwl\\tcloc\\tclof\\tclrv\\tcmrv\\tqerr\\tcobc\\tcmri\\tclri\\tcmrb\\tclrb\\tcmrs\\tclrs\\tclic\\tglcv\\tglca\\tlrdp\\tmrdp\\tcgmb\\tcgma\\tC106\\tC108\\tC111\\tC114\\tC206\\tC208\\tC211\\tC214\\tcoT1\\tcoT2\\tcprc\\tcpSF\\tcpRF\\tevap\\tepot\\ticpe\\tevsn\\tlevp\\tevpt\\tpsim\\tcrun\\tcro1\\tcro2\\tcro3\\tcrod\\tcros\\tros1\\tros2\\tacdf\\taqin\\taqut\\tspeq\\tgmlt\\tloff\\tlrfa\\tmrfa\\tlred\\tmred\\tinfi\\tsnwc\\tsnht\\tsnte\\tsnts\\tdtmp\\tcmrp\\tcrgl\\tcrnt\\tcmrr\\tcrpt\\tcrex\\tpsub\\tesub\\tisub\\tcmrq',\n",
       " '!! basinoutput meanperiod': 1,\n",
       " '!! basinoutput decimals': 3,\n",
       " '!! basinoutput subbasin': 'subid1\\tsubid2\\tsubid3\\tsubid4',\n",
       " '!! printwaterbal': 'N'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c72afac9-afd8-43ce-bc6a-49951470009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df6\n",
    "with open(output_file, 'a') as file:\n",
    "    for key,value in df6.items():\n",
    "        a=str(key)+'\\t'+str(value)+'\\n'\n",
    "        file.write(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87ccb9fe-d79a-435e-80d0-65bed6716160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s7\n",
    "s7= [\n",
    "\"\"\"!! -----------------\t\t\t\t\t\t\t\n",
    "!! TIME outputs \n",
    "!! -----------------\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1513cbf2-2ab7-404a-b4b5-47c98d6de188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s7 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s7:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "087634de-3cea-4579-86f1-ea1d4f3cb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7={'timeoutput variable': 'cout\\tevap\\tsnow', \n",
    "     'timeoutput meanperiod':1,\n",
    "     'timeoutput decimals':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fa57563-e3ce-44c3-8348-dd17d0d29366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timeoutput variable': 'cout\\tevap\\tsnow',\n",
       " 'timeoutput meanperiod': 1,\n",
       " 'timeoutput decimals': 3}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d509470b-10b5-47eb-a482-e01b3e916fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'a') as file:\n",
    "    for key,value in df7.items():\n",
    "        a=str(key)+'\\t'+str(value)+'\\n'\n",
    "        file.write(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0064daf-525d-4e09-8d6f-6768852500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s8\n",
    "s8= [\n",
    "\"\"\"!! -----------------\t\t\t\t\t\t\t\n",
    "!! MAP outputs\n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!! mapoutput variable\tcout cprc ctmp\n",
    "!! mapoutput decimals\t3\t\t\t\t\t\t\n",
    "!! mapoutput meanperiod\t5\t\t\t\t\t\t\n",
    "!! ------------------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! Select criteria for model evaluation and automatic calibration\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!! General settings\n",
    "!! -----------------\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a65b2fc7-e39f-41d5-9bf0-986076bae87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s8 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s8:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3b4a9c9-9ef4-4bec-99a9-f8a65d5ecff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8={'!! crit meanperiod': 1, \n",
    "     '!! crit datalimit':30,\n",
    "     '!! crit subbasin':'subid1\\tsubid2\\tsubid3\\tsubid4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5e73804-eb76-44fe-9728-0fddfca0572d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!! crit meanperiod': 1,\n",
       " '!! crit datalimit': 30,\n",
       " '!! crit subbasin': 'subid1\\tsubid2\\tsubid3\\tsubid4'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5beecaa7-a027-4136-8624-c487903f81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'a') as file:\n",
    "    for key,value in df8.items():\n",
    "        a=str(key)+'\\t'+str(value)+'\\n'\n",
    "        file.write(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cad0638d-a508-4022-8b41-845380139997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s9\n",
    "s9= [\n",
    "\"\"\"!! -----------------\t\t\t\n",
    "!! Criterion-specific settings\n",
    "!! -----------------\t\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39bdb8c8-0a82-4e97-b7bf-61e176411d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s9 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s9:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40b90d33-3a7e-4448-84b1-2b9c03df845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df9 for basin outputs\n",
    "d1=['MKG']\n",
    "d2=['cout']\n",
    "d3=['rout']\n",
    "d4=[1]\n",
    "df9_row=['crit 1 criterion','crit 1 cvariable','crit 1 rvariable','crit 1 weight']\n",
    "df9=pd.DataFrame([d1,d2,d3,d4], index=df9_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0da4554-74b6-4a04-8f91-65b908b35885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df9\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df9.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ea7de-ccc0-4cbd-993b-0297a0deceed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c42583-2716-4a03-b169-4ea1c3f08fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienv",
   "language": "python",
   "name": "scienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
