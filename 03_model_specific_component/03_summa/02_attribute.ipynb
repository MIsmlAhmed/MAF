{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4613f12b-114a-4493-a522-09b52de3d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages are loaded\n",
    "import xarray as xr\n",
    "import pint_xarray\n",
    "import glob\n",
    "import netCDF4 as nc4\n",
    "import os\n",
    "import pandas as pd\n",
    "from   easymore import Easymore\n",
    "import numpy as np\n",
    "from   easymore import Utility as esmrut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec63e4d-19a7-4a7d-a10b-8d8443d5e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "# Set the folder path where the remapped .nc file is located for MESH (it can be any remapped nc file)\n",
    "path_to_save = '/home/shg096/scratch/test/SUMMA/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d49cbc7-f662-435a-b6e2-7a943dd0f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = xr.open_dataset('/home/shg096/scratch/test/attr/attribute.nc')\n",
    "forcing = xr.open_dataset('/home/shg096/scratch/test/SUMMA/SUMMA_forcing.nc')\n",
    "\n",
    "# reorder based on the COMID order in the forcing\n",
    "attr = esmrut.reorder(attr,\n",
    "                      np.array(forcing['hru'].values),\n",
    "                      mapping = {'var_id':'COMID','dim_id':'n'})\n",
    "\n",
    "# prepare for the SUMMA attr file\n",
    "attr ['hruId'] = attr ['COMID']\n",
    "attr ['gruId'] = xr.DataArray(attr ['COMID'].values, dims=('gru'))\n",
    "attr ['hru2gruId'] = attr ['COMID']\n",
    "attr ['downHRUindex'] = xr.DataArray(np.zeros(len(attr['n'].values)), dims=('hru'))\n",
    "attr ['elevation'] = attr['mean_elev']\n",
    "attr ['HRUarea'] = attr['unitarea']\n",
    "attr ['tan_slope'] = xr.DataArray(np.ones(len(attr['n'].values)), dims=('hru'))\n",
    "attr ['contourLength'] = xr.DataArray(np.ones(len(attr['n'].values)), dims=('hru'))\n",
    "attr ['slopeTypeIndex'] = xr.DataArray(np.ones(len(attr['n'].values)), dims=('hru'))\n",
    "attr ['soilTypeIndex'] = xr.DataArray(attr ['soil_majority'].values.astype(int), dims=('hru'))\n",
    "attr ['vegTypeIndex'] = xr.DataArray(attr ['LULC_majority'].values.astype(int), dims=('hru'))\n",
    "attr ['mHeight'] = xr.DataArray(np.ones(len(attr['n'].values))*2, dims=('hru'))\n",
    "\n",
    "\n",
    "# List of variables to keep\n",
    "variables_to_keep = ['hruId', 'gruId', 'hru2gruId', 'downHRUindex',\\\n",
    "                     'elevation', 'HRUarea', 'tan_slope', 'contourLength',\\\n",
    "                     'slopeTypeIndex', 'vegTypeIndex', 'mHeight', 'longitude',\\\n",
    "                     'latitude', 'soilTypeIndex', 'latitude', 'longitude']\n",
    "# Drop variables not in the list\n",
    "attr = attr.drop_vars(set(attr.variables) - set(variables_to_keep))\n",
    "\n",
    "# rename the n dimension to hru\n",
    "attr = attr.rename({'n': 'hru'})\n",
    "\n",
    "attr\n",
    "\n",
    "if os.path.isfile(path_to_save+'SUMMA_attributes.nc'):\n",
    "    os.remove(path_to_save+'SUMMA_attributes.nc')\n",
    "\n",
    "attr.to_netcdf(path_to_save+'SUMMA_attributes.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f153c26-dd56-4632-8f23-0314da5896b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "hru_size = len(attr['hruId'].values)\n",
    "midSoil_size = 8\n",
    "midToto_size = 8\n",
    "ifcToto_size = 9\n",
    "scalarv_size = 1\n",
    "\n",
    "# Create a new xarray dataset\n",
    "ds = xr.Dataset()\n",
    "\n",
    "# Add dimensions to the dataset\n",
    "ds['hru'] = xr.DataArray(attr['hruId'].values, dims=('hru'), attrs={'units': '-'})\n",
    "ds['midSoil'] = xr.DataArray(range(midSoil_size), dims=('midSoil'))\n",
    "ds['midToto'] = xr.DataArray(range(midToto_size), dims=('midToto'))\n",
    "ds['ifcToto'] = xr.DataArray(range(ifcToto_size), dims=('ifcToto'))\n",
    "ds['scalarv'] = xr.DataArray(range(scalarv_size), dims=('scalarv'))\n",
    "\n",
    "# Add variables to the dataset\n",
    "ds['hruId'] = xr.DataArray(attr['hruId'].values, dims=('hru'), attrs={'units': '-', 'long_name': 'Index of hydrological response unit (HRU)'})\n",
    "ds['dt_init'] = xr.DataArray([[3600.0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['nSoil'] = xr.DataArray([[8] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['nSnow'] = xr.DataArray([[0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarCanopyIce'] = xr.DataArray([[0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarCanopyLiq'] = xr.DataArray([[0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarSnowDepth'] = xr.DataArray([[0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarSWE'] = xr.DataArray([[0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarSfcMeltPond'] = xr.DataArray([[0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarAquiferStorage'] = xr.DataArray([[1.0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarSnowAlbedo'] = xr.DataArray([[0] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarCanairTemp'] = xr.DataArray([[283.16] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['scalarCanopyTemp'] = xr.DataArray([[283.16] * hru_size], dims=('scalarv', 'hru'))\n",
    "ds['mLayerTemp'] = xr.DataArray([[283.16] * hru_size ] * midToto_size , dims=('midToto', 'hru'))\n",
    "ds['mLayerVolFracIce'] = xr.DataArray([[0] * hru_size] * midToto_size, dims=('midToto', 'hru'))\n",
    "ds['mLayerVolFracLiq'] = xr.DataArray([[0.2] * hru_size] * midToto_size, dims=('midToto', 'hru'))\n",
    "ds['mLayerMatricHead'] = xr.DataArray([[-1] * hru_size] * midToto_size, dims=('midSoil', 'hru'))\n",
    "# ds['iLayerHeight'] = xr.DataArray([[0.000,0.025,0.100,0.250,0.500,1.000,1.500,2.500,4.000]] * hru_size , dims=( 'hru', 'ifcToto',))\n",
    "# ds['mLayerDepth'] = xr.DataArray([[0.025,0.075,0.150,0.250,0.500,0.500,1.000,1.500]] * hru_size, dims=( 'hru', 'midToto',))\n",
    "ds['iLayerHeight'] = xr.DataArray(np.transpose([[0.000,0.025,0.100,0.250,0.500,1.000,1.500,2.500,4.000]] * hru_size) , dims=('ifcToto', 'hru'))\n",
    "ds['mLayerDepth'] = xr.DataArray(np.transpose([[0.025,0.075,0.150,0.250,0.500,0.500,1.000,1.500]] * hru_size), dims=('midToto',  'hru'))\n",
    "\n",
    "\n",
    "if os.path.isfile(path_to_save+'SUMMA_coldState.nc'):\n",
    "    os.remove(path_to_save+'SUMMA_coldState.nc')\n",
    "\n",
    "ds.to_netcdf(path_to_save+'SUMMA_coldState.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c9a5cb3-bd25-499e-8003-1373abddd295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "hru_size = len(attr['hruId'].values)\n",
    "\n",
    "# Create a new xarray dataset\n",
    "ds = xr.Dataset()\n",
    "\n",
    "# Add dimensions to the dataset\n",
    "ds['hru'] = xr.DataArray(attr['hruId'].values, dims=('hru'), attrs={'units': '-'})\n",
    "\n",
    "# Add variables to the dataset\n",
    "ds['hruId'] = xr.DataArray(attr['hruId'].values, dims=('hru'), attrs={'units': '-', 'long_name': 'Index of hydrological response unit (HRU)'})\n",
    "\n",
    "if os.path.isfile(path_to_save+'SUMMA_trialParams.nc'):\n",
    "    os.remove(path_to_save+'SUMMA_trialParams.nc')\n",
    "\n",
    "ds.to_netcdf(path_to_save+'SUMMA_trialParams.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd63ff-c452-40a2-af98-78559a650d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhimp_venv",
   "language": "python",
   "name": "fhimp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
